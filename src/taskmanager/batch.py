"""
Enhanced batch job manager with proper SLURM job submission
"""

import os
import subprocess
from pathlib import Path
from typing import List, Dict, Any, Optional
from .config import SlurmConfig
from .job_parser import JobParser
from .utils import TaskManagerError

class BatchManager:
    def __init__(self, config: SlurmConfig):
        self.config = config
        
    def generate_batch_script(self, jobs: List[Dict[str, Any]], output_file: str = "batch_job.sh", 
                            execution_mode: str = "sequential", dry_run: bool = False) -> str:
        """Generate complete batch submission script"""
        
        if execution_mode == "sequential":
            return self._generate_sequential_batch(jobs, output_file, dry_run)
        else:
            return self._generate_parallel_batch(jobs, output_file, dry_run)
    
    def _generate_sequential_batch(self, jobs: List[Dict[str, Any]], output_file: str, dry_run: bool) -> str:
        """Generate script that submits jobs with dependencies"""
        
        script_lines = [
            "#!/bin/bash",
            "# SLURM Batch Job Submission Script",
            "# Generated by TaskManager",
            "",
            "set -euo pipefail",
            "",
            "# Configuration",
            "DRY_RUN=" + ("true" if dry_run else "false"),
            "VERBOSE=true",
            "",
            "# Colors for output",
            "RED='\\033[0;31m'",
            "GREEN='\\033[0;32m'",
            "YELLOW='\\033[1;33m'",
            "NC='\\033[0m' # No Color",
            "",
            "log_info() { echo -e \"${GREEN}[INFO]${NC} $1\"; }",
            "log_warn() { echo -e \"${YELLOW}[WARN]${NC} $1\"; }",
            "log_error() { echo -e \"${RED}[ERROR]${NC} $1\"; }",
            "",
            "# Function to submit a job step",
            "submit_job_step() {",
            "    local script_path=\"$1\"",
            "    local dependency=\"$2\"",
            "    local job_type=\"$3\"",
            "    local nodes=\"$4\"",
            "    ",
            "    if [[ ! -f \"$script_path\" ]]; then",
            "        log_error \"Script not found: $script_path\"",
            "        return 1",
            "    fi",
            "",
            "    # Make script executable",
            "    chmod +x \"$script_path\"",
            "",
            "    # Generate SLURM submission script",
            "    local submit_script=\"submit_$(basename \"$script_path\" .sh).sh\"",
            "    generate_slurm_script \"$script_path\" \"$submit_script\" \"$job_type\" \"$nodes\"",
            "",
            "    # Build sbatch command",
            "    local sbatch_cmd=\"sbatch\"",
            "    if [[ -n \"$dependency\" ]]; then",
            "        sbatch_cmd=\"$sbatch_cmd --dependency=afterok:$dependency\"",
            "    fi",
            "    sbatch_cmd=\"$sbatch_cmd $submit_script\"",
            "",
            "    if [[ \"$DRY_RUN\" == \"true\" ]]; then",
            "        log_info \"Would execute: $sbatch_cmd\"",
            "        echo \"fake_job_id_$(date +%s)\"",
            "    else",
            "        log_info \"Submitting: $script_path\"",
            "        local job_id=$(eval \"$sbatch_cmd\" | grep -o '[0-9]\\+' | head -1)",
            "        if [[ -n \"$job_id\" ]]; then",
            "            log_info \"Submitted job ID: $job_id\"",
            "            echo \"$job_id\"",
            "        else",
            "            log_error \"Failed to submit $script_path\"",
            "            return 1",
            "        fi",
            "    fi",
            "}",
            "",
            "# Function to generate SLURM wrapper script",
            "generate_slurm_script() {",
            "    local original_script=\"$1\"",
            "    local slurm_script=\"$2\"",
            "    local job_type=\"$3\"",
            "    local nodes=\"$4\"",
            "",
            "    cat > \"$slurm_script\" << 'EOF'",
        ]
        
        # Add SLURM headers using the first job's config
        first_job = jobs[0] if jobs else {}
        job_type = first_job.get('job_type', 'production')
        nodes = first_job.get('nodes', 1)
        
        # Get SLURM headers
        headers = self.config.format_sbatch_headers(job_type, nodes).split('\n')
        script_lines.extend(headers)
        script_lines.extend([
            "",
            "# Change to job directory",
            "cd \"$SLURM_SUBMIT_DIR\"",
            "",
            "# Load modules",
            "module purge",
            "module load gromacs/2024.3-gcc-14.2.0",
            "",
            "# Execute the actual script",
            "bash \"$1\"",
            "EOF",
            "",
            "    # Replace placeholder with actual script path",
            "    sed -i \"s|\\$1|$original_script|g\" \"$slurm_script\"",
            "}",
            "",
            "# Main submission logic",
            "echo \"=== SLURM Batch Job Submission ===\"",
            "echo \"Execution mode: sequential\"",
            f"echo \"Dry run: {'yes' if dry_run else 'no'}\"",
            "echo",
            "",
            "prev_job_id=\"\"",
            ""
        ])
        
        # Add job submission commands
        for job in jobs:
            job_name = job.get('name', 'unknown')
            job_type = job.get('job_type', 'production')
            nodes = job.get('nodes', 1)
            scripts = job.get('scripts', [])
            path = job.get('path', '.')
            
            script_lines.append(f"# Job: {job_name}")
            
            for script in scripts:
                script_path = f"{path}/{script}"
                script_lines.extend([
                    f"log_info \"Submitting {script}...\"",
                    f"job_id=$(submit_job_step \"{script_path}\" \"$prev_job_id\" \"{job_type}\" \"{nodes}\")",
                    "if [[ $? -eq 0 ]]; then",
                    "    prev_job_id=\"$job_id\"",
                    f"    log_info \"Queued {script} with job ID: $job_id\"",
                    "else",
                    f"    log_error \"Failed to submit {script}\"",
                    "    exit 1",
                    "fi",
                    ""
                ])
        
        script_lines.extend([
            "if [[ \"$DRY_RUN\" == \"true\" ]]; then",
            "    log_info \"Dry run completed. No jobs were actually submitted.\"",
            "else",
            "    log_info \"All jobs submitted successfully!\"",
            "    log_info \"Monitor with: squeue -u $USER\"",
            "    log_info \"Check logs in: logs/\"",
            "fi"
        ])
        
        # Write the batch script
        with open(output_file, 'w') as f:
            f.write('\n'.join(script_lines))
        
        os.chmod(output_file, 0o755)
        return output_file
    
    def _generate_parallel_batch(self, jobs: List[Dict[str, Any]], output_file: str, dry_run: bool) -> str:
        """Generate script that submits all jobs in parallel"""
        
        script_lines = [
            "#!/bin/bash",
            "# SLURM Parallel Job Submission Script",
            "",
            "set -euo pipefail",
            "",
            "echo \"=== SLURM Parallel Job Submission ===\"",
            ""
        ]
        
        job_ids = []
        for i, job in enumerate(jobs):
            job_name = job.get('name', f'job_{i}')
            job_type = job.get('job_type', 'production')
            nodes = job.get('nodes', 1)
            scripts = job.get('scripts', [])
            path = job.get('path', '.')
            
            for script in scripts:
                script_path = f"{path}/{script}"
                job_var = f"job_id_{i}_{script.replace('.', '_').replace('-', '_')}"
                job_ids.append(job_var)
                
                if dry_run:
                    script_lines.append(f"echo \"Would submit: {script_path}\"")
                else:
                    script_lines.extend([
                        f"echo \"Submitting {script_path}...\"",
                        f"{job_var}=$(sbatch --parsable {script_path})",
                        f"echo \"Job {script}: ${job_var}\""
                    ])
        
        if not dry_run:
            script_lines.extend([
                "",
                "echo \"All jobs submitted. Job IDs:\"",
                *[f"echo \"  {job_id}: ${job_id}\"" for job_id in job_ids]
            ])
        
        with open(output_file, 'w') as f:
            f.write('\n'.join(script_lines))
        
        os.chmod(output_file, 0o755)
        return output_file